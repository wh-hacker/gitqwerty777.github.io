<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>計算機結構 (下) | QWERTY</title>
  <meta name="author" content="HCL">
  
  <meta name="description" content="Programming, Computer Science, Note">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="計算機結構 (下)"/>
  <meta property="og:site_name" content="QWERTY"/>

  
    <meta property="og:image" content="undefined"/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js" async></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-51310670-1', 'auto');
  ga('send', 'pageview');
</script>




  <script src="https://leancloud.cn/scripts/lib/av-0.4.6.min.js" async></script>
  <script>AV.initialize("j1wjgh5yjwypwyod6e73zq5pjr9bqgsjhlsnfi6fph67olbx", "lscxm6j2o23yn0vytcywijf1xzy0pwj826eey87aw6ndq9rf");</script>

</head>



 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">QWERTY</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> 計算機結構 (下)</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div class="col-md-9">
	

			

	<!-- content -->
	<div class="mypage">		
	    <h2 id="Chap07_Pipelining_(II)">Chap07 Pipelining (II)</h2><p><img src="/img/CA/detect-and-forward.png" alt="detect and forward"><br>Data Dependence Detection<br>Hazard conditions:</p>
<ul>
<li>EX hazard<ul>
<li>EX/MEM.RegisterRd = ID/EX.Register Rs or Rt </li>
</ul>
</li>
<li>MEM hazard<ul>
<li>MEM/WB.RegisterRd = ID/EX.RegisterRs or Rt</li>
<li>Ex/MEM.RegisterRd != ID/Ex.RegisterRs(優先選 EX)</li>
</ul>
</li>
<li>RegWrite == true</li>
<li>RegisterRd != $0<a id="more"></a>
Resolving Hazards by Forwarding<br><img src="/img/CA/forward.png" alt="forward"></li>
</ul>
<p>Add MUX to ALU inputs<br>Forwarding Control in EX<br><img src="/img/CA/forward-logic-mux.png" alt="logic with forward"></p>
<p>load-use data hazard(instruction after LW) -&gt; stall it  </p>
<pre><code>If <span class="list">(<span class="keyword">ID/EX</span>.MemRead and
<span class="list">(<span class="list">(<span class="keyword">ID/EX</span>.RegisterRt = IF/ID.RegisterRs)</span> or
<span class="list">(<span class="keyword">ID/EX</span>.RegisterRt = IF/ID.RegisterRt)</span>)</span>)</span>
    stall the pipeline
</code></pre><p>Stall: ID/EX 裡的 control value 改成 0，使 EX MEM WB 都不做事(nop) 並防止 PC 和 IF/ID register 更新，也就是確保他們下個 cycle 做跟這個 cycle 一樣的事<br>Insert a bubble: 空白的 instruction, 不做事<br><img src="/img/CA/bubble.png" alt="bubble"></p>
<p>Control Hazard Solutions</p>
<p>Branch 有沒有 taken 可以在 MEM 確認。如果發現 prediction 錯誤就重新設定 PC，並把 control 都設為 0，flush 掉跑錯的 instruction。<br>一個簡單的改進方式就是，在 ID stage 把資料從 register 讀出來後加上比較兩個值是否相等的元件，compare 完才進到 id/ex，這時候提早了一個 cycle 知道 branch 是否 taken。</p>
<p>當 branch 發生使用的值在 ALU 做完運算時，透過 forwarding 就可以解決了 <br> 但如果 branch 發生在使用的值正在 load 的話，就必須 stall。而如果是一 load 出來馬上就要做 branching 的判斷的話，就必須 stall 2 個 cycle<br><img src="/img/CA/2stall.png" alt=""></p>
<p>Dynamic prediction 的 branch history table，以 branch instruction 的 address(取最後 n 個 bit)做索引，並儲存 branch 的結果。如果猜錯的話就做之前一樣的 flush 並修改表。<br>跳出 loop 時會猜繼續，第一次進入 loop 會猜跳出 -&gt; 導致錯誤率大幅提高<br>-&gt; 2bit 的 predictor, 連續兩個 taken/not taken 才會改變狀態</p>
<p>但就算猜對，還是要算出 target address，所以在 branch taken 時會有一個 cycle 的 penalty。解決的方法是新增 buffer 存放 branch target address。</p>
<h3 id="Exception">Exception</h3><p>syscall，未定義的 opcode，或 overflow 處理等等 (以上為 CPU 內產生的指令) 或是受外部的 I/O 控制器的干涉。導致 performance 的降低。</p>
<ol>
<li>完成先前的指令</li>
<li>Flush the instruction in the IF, ID and EX stages</li>
<li>把這些違例或是被干擾的 instruction 的 PC(實際上是 PC+4)存在 Exception program counter(EPC)</li>
<li>問題的跡像 (indicator) 也存起來，在 MIPS 中是使用 Cause register</li>
<li>然後再跳到 handler(PC = 0x40000040)</li>
<li>另外一種解決的機制是，以硬體等級去告訴 I/O handler，根據不同的 cause 跳去不同的 handler(不同的 address)，instructions 要不就去執行 interrupt 的部份，要不就跳到 handler 去處理。</li>
<li>Handler 先讀看原因 (indicator) 然後再轉至專門解決此類問題的 handler，然後決定該採取什麼行動，如果是 restartable(可以重跑)，就用 EPC 回到原本執行的地方(EPC-4)，並採取判斷正確的行動。否則就終止程序並根據 EPC cause 來回報錯誤。</li>
</ol>
<p><img src="/img/CA/exception-handle.png" alt="step to handle exception"></p>
<p>ILP(instruction level parallelism)，指令層級的平行處理。<br>增進 ILP 的方法</p>
<ol>
<li>Deeper pipeline，把 pipeline 分成更多 stage，而每個 stage 因為 workload 相對的比較少，所以可以讓 cpu clock cycle 變短，進而增進效能</li>
<li>Multiple issue，有多個 pipeline 同時進行，所以每個 clock cycle 都同時跑好幾個 instruction。但是互相依賴性 (比如說不同 pipeline 之間的 hazard 或共用到哪些資源) 會使得實際上不是變幾倍的 pipeline IPC 就變幾倍。</li>
</ol>
<h3 id="Multiple_issue">Multiple issue</h3><p>可以分為 static 和 dynamic。<br>Static 的是由 compiler 把要同時執行的 instruction 包成一包一包的 instruction packets。<br>可以把 instruction packet 想成一個非常長的 instruction 裡面有好幾個同時運作的 operations。這樣的概念叫做 VLIW(very long instruction word)<br>偵測避免 hazard</p>
<ol>
<li>把 instruction 重新排列並包成 issue packets 時避免會造成 hazard 的順序。</li>
<li>同時在跑的 instruction 要互相 independent 不然就會搶資源或造成 data hazard。</li>
<li>在不同的 packets 之間，可以有 dependency，但這部份根據不同的 ISA 要有不同的設計。</li>
<li>有時候要放入 nop(不做任何動作)</li>
</ol>
<p>Dynamic 是由 CPU 選擇每個 cycle 要 issue 哪些 instructions，而 compiler 可以藉由把 instruction 串流做較好的排列來幫助。CPU 會用比較進階的技術在運行時解決 hazard。</p>
<p>Speculation：先去猜測要做什麼，如果做錯了再從頭來過。比如說 branch 的時候就先猜 taken 或 not taken，在 load 的時候先拿原有的位址去 load 如果發現其他該在前面的 instruction 更新了這個位址，就 roll-back。</p>
<p>Compiler 可以重新排列一些 code 比如說把 branch 之前的 load 移到更早，避免 stall，或是寫一些 instruction 來修正做出錯誤的 speculation 的狀況。增加用來延遲 exception 的 ISA。</p>
<p>而硬體可以做 look-ahead，將 instruction 的結果和 exception 都先存在 buffer 裡，直到他們要被用到或是判斷 speculation 正確。如果判斷 speculation 錯誤就把 buffer flush 掉。</p>
<h3 id="dual_issue">dual issue</h3><p>一個 packet 有兩組 instruction。一個只做 load/store 一個只做 ALU/branch，所以只要加一個 ALU 和一個 sign extender 就可以實做。</p>
<p>dual issue’s Data hazard:</p>
<pre><code><span class="built_in">add</span> <span class="bash"><span class="variable">$t0</span>, <span class="variable">$s0</span>, <span class="variable">$s1</span>
</span>load $s2, 0($t0)
</code></pre><p>把這兩個指令拆開放在兩個不同的 packets，就像 stall 一樣</p>
<p>Load-use hazard，一樣會造成一個 cycle 的延遲，但是一個 cycle 變成影響兩個 instructions。<br>-&gt; 需要把指令做更好的排程(aggressive scheduling)</p>
<p>loop unrolling: 把一次完成多個 loop 內的 iteration 來減少 loop-control overhead(bne)，並用不同的 register 來存放 (register renaming)(每一份 replicate 就是原本的 loop 跑一次)<br> 避免 loop 裡面有 anti–dependencies(name dependency): write-after-read<br>ex: B=7; A=B+1; B=3 在 a=b+1 和 b=3 之間就有 anti dependent 的關係</p>
<p><img src="/img/CA/unroll-before.png" alt="before"><br><img src="/img/CA/unroll-after.png" alt="after"><br>原本：for(load -&gt; 計算 -&gt; save)<br>之後：for(load) + for(add) -&gt; for(save)<br>IPC 從 1.25 提升到 1.75(更接近極限，2)不過 code 和 register 也變得更大。  </p>
<p>Dynamic multiple issue 通常在超大型處理器中使用。CPU 每個 cycle 會決定 issue 的對象。以幫助 cpu 對 code 的語義有更好的掌握 (compiler 做的事變少 CPU 更直接掌握 code 在做什麼)。<br>dynamic pipeline scheduling: 讓 cpu 可以不照順序執行 instruction 以避免 stall，但是會把資料<strong> 照順序存回</strong>register(比如說在 stall 的時候就先處理無關的 instruction)</p>
<p><img src="/img/CA/dynamic-schedule-CPU.png" alt="dynamic schedule CPU"><br>Dynamically scheduled CPU 的運作跟一般的 pipeline 有些出入，可以分為 4 個 stage</p>
<ol>
<li>IF/ID<br>照順序做完 instruction fetch 和 decode(這邊的動作很快)</li>
<li>reservation stations<br>控制哪些 instruction 要先 pending</li>
<li>functional units<br>做不同的功能 — 浮點數運算, load-store…<br>完成後把資料給 commit unit 及相對應在 pending 等這個結果的 reservation station</li>
<li>commit unit<br>重新排列 register write 要用的 buffer<br>並提供 operands 給某些在 reservation pending 的 function(類似之前單 issue 裡要 flush 重做的 function)</li>
</ol>
<p>?? Reservation station 和 commit unit 在 reorder buffer 時，自動達到了 register renaming。</p>
<p>?? 當一個 instruction 被 issue 到 reservation station 的時候，如果 instruction 的 operands 在 register 或 reorder buffer 裡可以被找到也可以被存取的話，把它複制到 reservation station，並且標明那個 register 已經無用可以被複寫。如果 operands 無法存取 (unavailable) 的話，有一個 function unit 會把該給的值給 reservation unit，而 register 裡面的值需不需要更新就要看指令。</p>
<p>dynamically scheduled 的 speculation: 在 branching 的結果確認之前不要 commit。而 speculation 一樣可以用在減少 load 和 cache miss delay。根據預測的 address 先取出值然後等 store 有沒有更改到這個 load 的 address，store 會把那個 address bypass 到 load unit。沒問題就把結果送到 commit unit，有問題就重做。</p>
<p>Dynamically scheduling 的原因:<br>不是所有的 stall 都是可以從 code 裡看出來的 比如說:cache miss。<br>branch 的結果也不能靠 scheduling 來解決。<br>不同的 ISA 有不同的延遲和不同的 hazard，都要交給 compiler 來處理實在非常麻煩。</p>
<p>Multiple issue 的效能：程式內有 dependency 會限制 ILP(instruction level parallelism)而且有些 dependency 很難去除，如 pointer aliasing(不同的名字的 pointer 指到同一個地方)<br>有一些平行也很難做到比如說 IF/ID 的部份<br>memory 還有 delay 而且也有他的頻寬，也導致 pipeline 常常有 nop<br>Speculation 如果做的好的話可以改善以上原因引起的 performance 下降</p>
<p>多顆簡單的核心 (沒 speculation, issue width 低, pipeline, stage 少) 可以達到省電的作用</p>
<h3 id="結論">結論</h3><p>pipeline 的概念很簡單，但是細節很複雜。Ex: hazard detection<br>pipeline 跟 cpu 的其他科技無關，其他科技進步的同時還是可以做 pipelining  </p>
<p>不好的 ISA 設計可能在某些狀況下會讓 pipelining 變得很困難 <br>ex:<br> 太複雜的 instruction set 需要巨大的 overhead 來讓 pipeline 可行 (ex: IA-32,VAX)<br> 太複雜的 addressing mode<br>間接讀取 memory(指標)，及 register update<br>複雜的 pipeline，會有比較長的 branching delay slots  </p>
<p><strong>ISA 會影響 data path 和 control 的設計</strong><br>Pipelining 利用平行處理的技術可以提高總輸出，並不影響單個指令的 latency<br>Dependency 限制了平行處理的程度，太過複雜又會導致電耗過高</p>
<h2 id="Chap08_Memory_Hierarchy">Chap08 Memory Hierarchy</h2><p><img src="/img/CA/memory-hierarchy.png" alt="hieraracy"><br>記憶體的層級化: 愈常用的放在愈快拿到的地方</p>
<ul>
<li>Static Ram: 0.5ns-2.5ns， 每 gb 要 2000 – 5000 元</li>
<li>Dynamic Ram: 50ns -70ns 每 gb 要 20- 75 元</li>
<li>硬碟:5-20ms，每 gb 只要 0.2-2 元</li>
</ul>
<p>Temporal locality: 最近被存取過的 data 容易再被存取<br>Ex: 在 loop 裡面的程序，或是在 loop 裡面一直被重複操作的數字</p>
<p>Spatial locality: 位址接近最近被存取過的 data 較有可能被存取，如 array</p>
<p>資料的 copy 以 block 為最小單位。<br>Hit Time: memory access time + time to determine hit/miss<br>Miss Penalty: Time to replace a block in the upper level + Time to deliver the block to processor  </p>
<p>direct mapped cache: mod 餘 1, mod 餘 2 … 各放在同一個 cache block<br>memory address 前面的 bit 也存過去做為 tag，可知道是從 memory 的哪個位置將資料 load 到這個 cache<br>Valid bit 可以很快的判斷一個 block 裡面是否有資料<br><img src="/img/CA/direct-map.png" alt="direct map"></p>
<p>Q:How many total bits are required for a direct-mapped cache with 16 KB of data and 4-word(16byte) blocks, assuming 32bit address?</p>
<ul>
<li>num of sets = 16KB(cache size)/16B(block size) = 2^10</li>
<li>num of data bits for each set = 16byte data = 4</li>
<li>num of tag bits for each set = 32-10-4 = 18</li>
</ul>
<p>Cache Controller FSM<br><img src="/img/CA/cache-controller-fsm.png" alt="FSM"></p>
<h3 id="考慮因素">考慮因素 </h3><p> 若增大 block size，block 數變少，有利於 spatial locality，但 miss penalty 上升</p>
<p>解決 miss penalty 上升  </p>
<ul>
<li>Early restart：正常運作，只要一 fetch 到需要的 word，就馬上把這個 word 送到 CPU</li>
<li>Critical word first：先 fetch 需要的 word，再把剩下的 word 填進 cache bloc</li>
</ul>
<p>各層級的資料不同步</p>
<ul>
<li>Write through：寫入 cache 時同時寫入 memory</li>
<li>Write back：cache 被代替時，再寫入 memory，設 dirty bit</li>
<li>使用 write buffer：只有在 write buffer 滿的時候才 stall</li>
</ul>
<p>Write Miss Policy</p>
<ul>
<li>Write allocate(fetch on write): 先 load 到 cache 再修改</li>
<li>No Write allocate(write around): 直接 write 底層的資料，不 load 到 cache</li>
</ul>
<p>在做初始化時，寫入的資料 (全都是 0) 不會在近期內就被讀取，採取 write around 就是一個比較好的選擇</p>
<p>是否合併 instruction cache 和 data cache?  </p>
<ul>
<li>Combined cache – higher cache hit rate &amp; lower cache bandwidth   </li>
<li>Split cache – lower cache hit rate &amp; higher cache bandwidth</li>
</ul>
<p>memory interleave: 讓 BUS 可以同步讀取不同 BANK<br><img src="/img/CA/memory-interleave.png" alt="memory design"></p>
<ul>
<li>DDR: RAM 不只在 clock 0 變 1 時動作，在 1 變 0 的時候也做一次動作，使 data rate 變為兩倍故名 ddr</li>
<li>QDR: DDR 再加上將 input 和 output 分開，在同一個 clock 變更時可以同時做 input 和 output 的技術</li>
</ul>
<p>當 CPU 的效能增進時，miss penalty 的影響就越來越大</p>
<p>How to Improve Cache Performance?</p>
<ol>
<li>Reduce miss rate -&gt; Increasing associativity<br> direct mapped -&gt; set associative -&gt; fully associative<br> 效能提升呈邊際遞減<br> 缺點：mux delay, data comes after hit/miss, tag bit increase</li>
<li>Reduce miss penalty -&gt; multi-level cache<br> high performance improvement<br> Ex. radix sort: cache miss rate high, so performance worse than quick sort</li>
<li>Reduce hit time -&gt; small cache(…)</li>
</ol>
<p>記憶體的層級化(memory hierarchy)：每一層裡面都有 4 個重點，block 要怎麼放置，要怎麼找到需要的 block，當 miss 的時候怎麼替換，寫入時的規矩(write policy)。</p>
<ol>
<li>block 要怎麼放置: 由 associativity 決定。可分為 direct mapped, n-way, 和 fully associative。越高的 associatvie 就越少 miss 但是 cost，access time 和複雜度也越高。(三種 associative 參考前面)</li>
<li>要怎麼找到需要的 block: direct mapping 需要做 1 次的 comparison，n-way 需要做 n(看多少 way)次，而 fully associative 如果建表就不用沒的話就要做 entry 的次數次(每個 entry 都要比對)。這邊我們的目標是降低 comparison 以降低硬體 cost。VM 由於 full look-up table 的查表方式使得 fully associative 可行，可以大大降低 miss rate。</li>
<li>當 miss 的時候怎麼替換(algo): 替換的方法有 LRU 和 random 兩者比較在前面講過了。在 VM 裡面的話我們藉由硬體的幫忙實作 LRU。</li>
<li>Write policy:write-through 和 write-back，在 VM 裡只有 write-back 可行(28 點)。</li>
</ol>
<h2 id="Chap_08-2_Virutual_Memory">Chap 08-2 Virutual Memory</h2><p>Idea: use memory as cache for disk  </p>
<p>block 叫做 page，miss 叫做 page fault</p>
<p>Disk 讀取的速度非常慢，要花上百萬個 cycle。必須使用 Fully associative 和較佳的 replacement algorithm，及軟體為主的 exception handler</p>
<p>page fault 發生時，os 會把相對應的 page 抓進來並 update page table 然後再重新執行導致 page fault 的 instruction</p>
<p>LRU replacement: 每個 PTE(entry)加個 bit 叫 reference bit，每次當這個 page 被 access 就把這個 reference bit 設為 1，然後系統會自動定期將所有 reference bit 清為 0，這樣我們可以判斷 reference bit 是 0 的 page 最近沒有被 access。</p>
<ol>
<li>Page table: 由 virtual page number 作 index，值為 physical index。</li>
<li><p>Page table can be very large!<br>–Solution: inverted page table &amp;  multi-level paging</p>
</li>
<li><p>inverted page table: use hash to search(非常耗時、無法支援 Memory sharing)</p>
</li>
<li><p>multi-level: 分層, decrease total page table size<br><img src="/img/CA/multilevel-pagetable.png" alt="two-level"></p>
</li>
<li><p>TLB(translation look-aside buffer)可以很快的 cache 在 cpu 內存放 PTE。通常可存放 16~512 個 PTE，hit 時只要花 0.5~1 個 cycle，miss 的話也只要 10~100 個 cycle。並且有 0.01%~1% 的低的 miss rate</p>
</li>
</ol>
<p>不同的任務 (task) 有時候可以共用他們的虛擬位址，但是需要 OS 的協調指派，並防止不相干的程式的 access。<br>需要硬體的支援: kernel mode, 包含特有的 instruction. page table 和他的 state 資訊只有在 kernel mode 下可以 access。並且還要有 system call exception</p>
<p><img src="/img/CA/memory-retrieve-events.png" alt="Possible Combinations of Events"></p>
<p>Virtually Addressed Cache only Translated on miss</p>
<p>distinguish data of different processes<br>-&gt; Virtually indexed &amp; physically tagged cache<br>-&gt; read data by tag and translate index in the same time<br><img src="/img/CA/vipt-flow.png" alt="Virtually indexed &amp; physically tagged cache"></p>
<h3 id="Performance_issue_in_Virtual_Memory">Performance issue in Virtual Memory</h3><p>Thrashing Solutions: Buy more memory<br>High TLB misses Solutions:Variable page size</p>
<ol>
<li>compulsory misses，也叫做 cold-start misses。資料第一次被存取。</li>
<li>capacity misses，cache 的大小有限，一個剛被 replace 掉的 block 馬上又需要被 access。</li>
<li>conflict misses(collision misses)。多個 block 要競爭同一個 index 的 entry，如果是 fully-associative 就不會發生<br><img src="/img/CA/collision-miss-rate.png" alt="3C absoluate miss rate"></li>
</ol>
<p>若想要減低 miss rate, 就會造成總體效能的負面效應。<br>Trends:<br>–Redesign DRAM chips to provide higher bandwidth or processing<br>–Use prefetching &amp; non-blocking cache (make cache visible to ISA)<br>–Restructure code to increase locality</p>
<p>Reduce miss penalty</p>
<ul>
<li>Non-blocking caches<ul>
<li>Non-blocking cache or lockup-free cache allowing the data cache to continue to supply cache hits during a miss</li>
</ul>
</li>
<li>Prefetching<ul>
<li>Requesting data early, so it’s in cache when needed.</li>
<li>預測技術(complier or hardware)</li>
<li>Problem: May replace data in cache that is still needed.</li>
</ul>
</li>
</ul>
<p>VMM(virtual machine monitor)將虛擬的資源 map 到實體資源上，ex: memory I/O, CPU。guest 的 code 在我們的本機端跑時是使用 user mode，VMM 可以控管一些要有權限才能用的 instructions 和一些資源是否可以 access。Guest 的 os 可能跟我們使用不同套，於是 vmm 就要產生一個虛擬的 I/O 給 guest 使用，來處理真正的 I/O。<br>如果 VM request 一個 timer-interrupt，這時候 vmm 就會根據本機的 timer 虛擬出一個虛擬的 timer。利用這個 timer 來判斷 interrupt 的發生。<br>在 vm 上所有必須 access 實體資源的動作都要透過由 VMM 監控的 privileged instructions 才使用。比如說 page tables, I/O , interrupt controls, registers 等。<br>做某一些動作比如說要建立多重的 web service 時，所有東西都要經過 VMM，VMM 就回成為一個很大的 threshold。</p>
<h2 id="Chap_10_Storage,_Network_and_Other_Peripherals">Chap 10 Storage, Network and Other Peripherals</h2><p><img src="/img/CA/iosystem.png" alt="IO System"></p>
<p>I/O Device Characteristics</p>
<ul>
<li>behavior<ul>
<li>input, output or storage</li>
</ul>
</li>
<li>partner</li>
<li>data transmit rate</li>
</ul>
<p>performance metrics: Throughput, Response time<br><img src="/img/CA/iodevicechart.png" alt="I/O device characterstics"></p>
<p>I/O System performance: find limited by weakest link in the chain<br>: CPU, memory, bus, IO controller, IO device, OS, software<br>Two common </p>
<p>reliability</p>
<ul>
<li>MTTF: 平均要多久會出現一次 failure</li>
<li>MTTR: 平均遇到 failure 以後多久會修好</li>
<li>availability 是 MTTF/(MTTF+MTTR)</li>
<li>改進 availability<ul>
<li>增進 MTTF，有避免 fault 的發生，減少 fault 發生時造成的損失，還有 fault 的預測</li>
<li>減少 MTTR，加強 repair，增強 fault 的原因的分析功能，還有 repair 的機制</li>
</ul>
</li>
</ul>
<p>Disk Performance<br>seek time: 上下移動<br>Rotational latency: 轉到讀取的資料所需時間(RPM)，平均計算：轉一半(0.5round)<br>transfer rate: 傳送資料速度<br>Controller time: I/O controller 花的時間</p>
<p>快閃記憶體 (flash) 比硬碟快上 100~1000 倍。<br>比較小，比較不耗電。但是比較貴(介於 disk 和 dram 之間。)<br>Flash 可以分為 NOR 或 NAND flash。<br>NOR flash 是 random access 通常用在嵌入式系統的 instruction memory。<br>NAND 同時只能 access 某個 block，而且同樣的大小有比較大的容量。成本也比較低。通常用來當我們常用的 usb drive 或記憶卡，SSD 等等。<br>Flash 的 bit 約在 access 千次以後會壞掉。所以不適合拿來做 ram 或硬碟。解決方法是把 data 平均放在每個 block 上。</p>
<p>flash’s block: 包含多個 page</p>
<ol>
<li>Write Once: 無法直接覆蓋檔案，需先清除，一次清除一個 block</li>
<li>When # of free pages &lt;= Garbage Collection Threshold<br>: move live page to other block , and erase this block</li>
</ol>
<p>SSD (Solid Storage Disk)<br>no actual “disk”, use integrated circuit assemblies as memory to store data persistently.<br>SSD uses electronic interfaces compatible with traditional block drives</p>
<ul>
<li>no mechanical failure</li>
<li>Green<ul>
<li>SSDs consume over 50% less power compared to HDD</li>
</ul>
</li>
<li>Higher initial cost</li>
<li>Ex. Facebook data center</li>
<li>Active SSD: 在 I/O 端作 (簡單的) 計算，減少 L/W 時間</li>
</ul>
<p>將 PCI-e flash 作為 I/O cache(比 SSD 快！)放在 General IO bus 上以加速 I/O</p>
<p>Bus: Connection between Processors, Memory, and I/O Device<br>有很好的同步性和低維護費，但造成效能瓶頸 (受限於長度，BUS 數目…)<br> 有 Control line 和 Data line</p>
<p>Bus 可以分為</p>
<ul>
<li>Processor-memory bus: 較短較快，要照著 memory 的規劃做設計</li>
<li>I/O bus: 較長，可以有多重的互相連結。要照著互通性的基準設計</li>
<li>Backplane bus: 所有 device 都可連接，花費較少，用來連接前兩者</li>
</ul>
<p><img src="/img/CA/three-type-bus.png" alt="three bus system"></p>
<p>Synchronous Bus: </p>
<ul>
<li>includes a clock in the control lines</li>
<li>advantage: involves very little logic and can run very fast</li>
<li>disadvantages: <ul>
<li>every device on the bus must run at the same clock rate</li>
</ul>
</li>
</ul>
<p>Asynchronous Bus:</p>
<ul>
<li>No clock, can accommodate a wide range of devices</li>
<li>can be lengthened without worrying about clock</li>
<li>requires a handshaking protocol<br><img src="/img/CA/asynchronous-handshaking.png" alt="Asynchronous handshaking: Read Transaction"></li>
</ul>
<p>Multiple Potential Bus Masters: use Arbiter to control<br>Arbiter: select who can use bus by priority and fairness</p>
<p>Daisy Chain Bus Arbitrations<br><img src="/img/CA/daisy-chain.png" alt="Daisy Chain Bus Arbitrations"><br>Advantage: simple<br>Disadvantages:<br>–Cannot assure fairness: A low-priority device may be locked out indefinitely<br>–The use of the daisy chain grant signal also limits the bus<br>speed</p>
<p>Centralized Parallel Arbitration<br><img src="/img/CA/Centralized-Parallel-Arbitration.png" alt="Centralized Parallel Arbitration"><br>所有 bus 由 arbiter 控管 <br> 適合速度較快的 device 組成的 bus</p>
<p>I/O 的設備是由 I/O controller 來管理並同步。<br>command register 來存放不同的 command 使用不同的 command 來讓 I/O device 執行不同的動作<br>status register 來指出 I/O 設備現在正在執行什麼 task 還有是否遇到什麼 error<br>data register，可以把 data “write”到 device 或從 device ”read”出 data。</p>
<p>Memory mapped I/O<br>I/O 的 register 的位址設為跟 memory 中的位址一樣，只有在 kernel mode 時可以 access 這些 address</p>
<p>Communicating with the Processor<br>‧Polling<br>定期檢查 I/O status register，如果是 ready 就執行 I/O，如果是 error 就想辦法解決。叫 polling(問卷調查)。會浪費太多 cpu time(busy loop)。<br>有反應時間需求時使用 <br>‧Interrupt<br><img src="/img/CA/interrupt-driven-IO.png" alt="Interrupt Driven Data Transfer"><br> 當 ready 或 error 時，controller 就會 interrupt CPU。<br>Interrupt 跟 exception 很像，但可以在兩個 instruction 之間觸發 handler。通常可以由 cause 的資訊來分辨是哪個 device 發生 interrupt。Interrupt 也有不同的 priority，越緊急的 interrupt priority 就會越高。也可以用高 priority 的 interrupt 來呼叫低 priority 的 interrupt 的 handler。<br>high-speed devices are associated with higher priority<br>‧DMA(direct memory access)<br>I/O controller 主動跟 memory 連結傳輸資料，直到傳輸完成或是 error 才 interrupt。比較節省 cpu-time。<br>DMA 寫到 memory 後，可能造成 memory 和 cache 不一致 <br> 如果 write-back cache 有 dirty block 而 DMA 去讀到相對應的 memory 的話也會讀到錯誤的資料。解法：cache 的內容如果在 memory 中被 dma 寫入就把那個 cache flush 掉，不然就要設定 noncacheable(dma 不能動在 cache 的資料)。</p>
<p>Parallelisms and I/O</p>
<p>RAID: Redundant Array of (inexpensive)Independent Disks。<br>使用很多個小的 disk 來取代一個大的 disk，好處有資料較不易受損和平行處理速度加快<br>‧Improve availability with redundancy</p>
<p>Raid 0，是最早的 RAID，沒有 redundancy，只是把資料分散在不同的小 disk 可以平行讀取 <br>RAID 1(Disk Mirroring): 是兩個一模一樣的 disk，一個是當作備份用，如果主 disk 的資料受損就從 mirror copy 過去<br>RAID 2: 把資料拆到以 bit 為單位分散的存在 disk 內。並用 E-bit 來做 Error correction。拆到以 bit 為單位的話假設有 n 個 disk 則要讀任何資料理論上可以有 n 倍快。但是太複雜的設計導致實際上 raid2 並沒有在使用。只用於 memory<br>Raid3(Bit-Interleaved Parity):<br> 使用 N+1 個 disk，資料拆成 bit level 分散在 n 個 disk 上 <br> 用剩下來的 disk 存 parity(前面 n 個 disk 裡相對應的位址的每個資料做 XOR)<br>在 read 時就讀取所有的 disk，在 write 時寫入每個 disk 並產生新的 parity。遇到 failure 時根據 parity 可以判斷 failure 的 bit。<br>RAID4:<br>跟 raid3 很像只是是拆成 block level，每次要讀資料時只要讀存放所需資料的 block 就好，寫資料也只需要動到要寫的 block 和 parity。<br>RAID5:<br>跟 RAID4 接近，但是把 parity 分散存至每個 disk 以避免 parity disk 成為在寫入時的速度的瓶頸 (Raid4 每個寫入都要寫 parity disk，所以 parity disk 寫入的速度就會限制資料寫入的速度)<br>RAID6(P + Q Redundancy):<br> 跟 RAID5 一樣但是增加兩個 parity(不同演算法)，使系統容錯率更高。</p>
<p>RAID summary:<br>raid 可以提升 performance 並增加可靠性 (hot swapping，在不影響系統 operate 的情形下修復 fault)<br> 可靠性是 raid 最重要的功能。</p>
<p>Disk I/O Benchmarks: I/O rate vs. Data rate vs. latency</p>
<h2 id="Chap12_Multicores,_Multiprocessor">Chap12 Multicores, Multiprocessor</h2><p>Challenges</p>
<ul>
<li>Partitioning</li>
<li>Coordination</li>
<li>Communication overheads</li>
<li>Amdahl’s Law<br>平行化是有極限的<br>  FracX: 能被 speedup 的比例<br>  Speedup = 1 / [(FracX/SpeedupX + (1-FracX)]</li>
</ul>
<p>資料傳遞<br>Shared Memory: connect by memory<br>use lock to synchronize<br>same address space<br>Message Passing: connect by network<br>different address spaces</p>
<p>Total network bandwidth = 所有的頻寬。bandwidth-per-link x link_no<br>Bisection bandwidth = 兩個部分之間的頻寬。the bandwidth between two parts of a multiprocessor</p>
<p><img src="/img/CA/network-topology.png" alt="netword topology"></p>
<p>Cache Coherency Problem: 在 cache 中的共享資料須保持一致<br>Protocol:</p>
<ol>
<li>Snoopy Bus: use for small scale machines<br>在拿資料前，先 boardcast 給所有 processor 知道 <br>allow multiple readers, single writer<br>Broadcast: BW (increased) vs. latency (decreased) tradeoff<br>Write Invalidate Protocol:<br> 若寫資料，也 boardcast，其他有同資料的 processor 設 invalid bit<br>Write Update Protocol:<br>若寫資料，也 boardcast，其他有同資料的 processor 作相同的 instruction</li>
</ol>
<p>Each block of memory is in one state:<br>    –Clean in all caches and up-to-date in memory<br>    –OR Dirty in exactly one cache<br>    –OR Not in any caches<br>Each cache block is in one state:<br>    if read miss, place readmiss on bus, goto shared<br>    if write miss, place writemiss on bus, goto exclusive<br>    if get read miss at bus(same block), if at exclusive, do write back and goto shared<br>    if get write miss at bus, goto(set) invalid<br>    –Shared: block can be read<br>    –OR Exclusive: cache has only copy, its writeable, and dirty<br>    –OR Invalid: block contains no data<br><img src="/img/CA/IO-BUS-fsm.png" alt="State machine for bus requests for each cache block"><br><img src="/img/CA/IO-CPU-fsm.png" alt="State machine for CPU requests for each cache block"></p>
<ul>
<li>Basic CMP Architecture Shared last level cache</li>
<li>Scalable CMP Architecture Tiled CMP<ul>
<li>Each tile includes processor, L1, L2, and router</li>
<li>Physically distributed last level cache</li>
</ul>
</li>
</ul>
<p>Multithreading<br><img src="/img/CA/multithreads.png" alt="Multithreaded Categories p53"></p>
<ul>
<li>實作多執行緒<ul>
<li>有多個 registers, PC</li>
<li>Fast switching between threads</li>
<li>減少 stall 的時間浪費</li>
</ul>
</li>
<li>Fine-grain multithreading(一個 cycle 做一個 thread 的多個 cycles)</li>
<li>Coarse-grain multithreading(只有大的 stall(L2 cache miss)才切換 thread)</li>
<li>Simultaneous Multithreading<ul>
<li>used in dynamically scheduled processor</li>
<li>同一個 cycle 可做多個 thread</li>
<li>dependencies handled by scheduling and register renaming</li>
</ul>
</li>
<li>和 Multiprocessing 的不同：multiprocessing 需多個 processor</li>
</ul>
<p>費林分類法（Flynn’s Taxonomy），是一種高效能計算機的分類方式</p>
<ul>
<li>單一指令流單一資料流計算機（SISD）  </li>
<li>單一指令流多資料流計算機（SIMD）<ul>
<li>processors execute the same instruction at the same time.Each with different data address</li>
<li>Works best for highly data-parallel applications</li>
<li>Vector architecture</li>
<li>Explicit statement of absence of loop-carried dependences(Reduced checking in hardware)</li>
<li>Avoid control hazards by avoiding loops  </li>
</ul>
</li>
<li>多指令流單一資料流計算機（MISD）</li>
<li>多指令流多資料流計算機（MIMD）  </li>
<li>SPMD: Single Program Multiple Data<ul>
<li>A parallel program on a MIMD computer</li>
<li>Conditional code for different processors</li>
</ul>
</li>
</ul>
<p>GPU(Graphics Processing Units)</p>
<ul>
<li>compute massive vertices, pixels, and general purpose data</li>
<li>High availability</li>
<li>High computing performance</li>
<li>Low price of computing capability</li>
</ul>
<p>General-Purpose computing on GPU (GPGPU)<br>用處理圖形任務的圖形處理器來計算原本由中央處理器處理的通用計算任務，這些通用計算常常與圖形處理沒有任何關係。由於現代圖形處理器強大的並行處理能力和可程式流水線，令流處理器可以處理非圖形數據。特別在面對單指令流多數據流（SIMD），且數據處理的運算量遠大於數據調度和傳輸的需要時，通用圖形處理器在性能上大大超越了傳統的中央處理器應用程式。</p>
<p>GPGPU programming models</p>
<ul>
<li>NVIDIA’s CUDA</li>
<li>AMD’s StreamSDK</li>
<li>OpenCL</li>
</ul>
<p>Multi-core CPU</p>
<ul>
<li>Coarse-grain, heavyweight threads</li>
<li>Memory latency is resolved though large on-chip caches &amp; out-of-order execution<br>Modern GPU</li>
<li>Fine-grain, lightweight threads</li>
<li>Exploit thread-level parallelism for hiding latency</li>
<li>SIMT (Single Instruction Multiple Threads)<ul>
<li>multiple independent threads(pixel, vertex, compute…) execute concurrently using a single instruction</li>
<li>common PC value</li>
<li>Latency Hiding</li>
</ul>
</li>
</ul>
<p>Serial/Task-parallel workloads → CPU<br>Graphics/Data-parallel workloads → GPU<br>Behaviors of the applications are different<br>-&gt; CPU is latency sensitive, GPU is throughput oriented</p>
<h3 id="參考資料">參考資料</h3><p>CA_by_b95015.doc</p>
	  
	</div>

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/computer-network2/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>上一頁</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/lua錯誤記錄/" class="alignright next">下一頁<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">留言</h2>

  
  	 <div id="disqus_thread">
     <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  	 </div>
  
</section>

	
	</div> <!-- col-md-9/col-md-12 -->
	
	
		<div class="col-md-3"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2014-11-25 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/筆記/">筆記<span>13</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/computer-architecture/">computer architecture<span>2</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Chap07_Pipelining_(II)"><span class="toc-article-text">Chap07 Pipelining (II)</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Exception"><span class="toc-article-text">Exception</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Multiple_issue"><span class="toc-article-text">Multiple issue</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#dual_issue"><span class="toc-article-text">dual issue</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#結論"><span class="toc-article-text">結論</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Chap08_Memory_Hierarchy"><span class="toc-article-text">Chap08 Memory Hierarchy</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#考慮因素"><span class="toc-article-text">考慮因素 </span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Chap_08-2_Virutual_Memory"><span class="toc-article-text">Chap 08-2 Virutual Memory</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Performance_issue_in_Virtual_Memory"><span class="toc-article-text">Performance issue in Virtual Memory</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Chap_10_Storage,_Network_and_Other_Peripherals"><span class="toc-article-text">Chap 10 Storage, Network and Other Peripherals</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Chap12_Multicores,_Multiprocessor"><span class="toc-article-text">Chap12 Multicores, Multiprocessor</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#參考資料"><span class="toc-article-text">參考資料</span></a></li></ol></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	

</div><!-- row -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2015 HCL
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>

<script type="text/javascript">
var disqus_shortname = 'githubforqwerty';
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<!--mathjax-->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>      


<!--leancloud page counter-->
<script>
function addCount (Counter) {
        var title = $("page-header").context.title.split('|')[0].trim();
	var url = "/" + $('.mytitle').context.URL.split("/")[3] + "/";
        var query=new AV.Query(Counter);
        //use url as unique idnetfication
        query.equalTo("url",url);
        query.find({
            success: function(results){
                if(results.length>0)
                {
                    var counter=results[0];
                    counter.fetchWhenSave(true); //get recent result
                    counter.increment("time");
                    counter.save();
                }
                else
                {
                    var newcounter=new Counter();
                    newcounter.set("title",title);
                    newcounter.set("url",url);
                    newcounter.set("time",1);
                    newcounter.save(null,{
                        success: function(newcounter){
                        //alert('New object created');
                        },
                        error: function(newcounter,error){
                        alert('Failed to create');
                        }
                        });
                }
            },
            error: function(error){
                //find null is not a error
                alert('Error:'+error.code+" "+error.message);
            }
        });
}
$(function(){
        var Counter=AV.Object.extend("Counter");
        //only increse visit counting when intering a page
	var titleName = $('h1')[0].textContent.trim()
        if ($('.mytitle').context.URL.split("/")[2] != "localhost:4000" && $('title').length == 1 && titleName != "QWERTY" && titleName != "Categories" && titleName != "Tags" && titleName != "彙整")
           addCount(Counter);
        var query=new AV.Query(Counter);
        query.descending("time");
        // the sum of popular posts
        query.limit(10); 
        query.find({
            success: function(results){
				
                    for(var i=0;i<results.length;i++)    
                    {
						//alert(results[i]);
                        var counter=results[i];
                        title=counter.get("title");
                        url=counter.get("url");
                        time=counter.get("time");
                        // add to the popularlist widget
                        showcontent=title+" ("+time+")";
                        //notice the "" in href
                        $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                    }
                },
            error: function(error){
                alert("Error:"+error.code+" "+error.message);
            }
            }
        )
        });
</script>

</body>
   </html>
